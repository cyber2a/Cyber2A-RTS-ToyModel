{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "garden_display_metadata_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f25917340d400895200b586a05889b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Accordion(children=(Textarea(value='', continuous_update=False, placeholder='Global Garden DOI'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f25319a7d444a5b6dd4ddb6429c594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is auto-generated by Garden.\n",
    "You can use this widget to edit your notebooks metadata. \n",
    "That way, the next time you run this notebook, Garden will start it with the same environment.\n",
    "Any changes made to your notebook's metadata using the widget will be saved when the notebook is saved.\n",
    "\n",
    "Notebook metadata fields:\n",
    "   - Global Garden DOI: If specified, `garden-ai notebook publish` will add all entrypoints in this notebook to the Garden with the given DOI.\n",
    "     If you want to specify a different Garden DOI for individual entrypoints, you can provide that entrypoint's\n",
    "     'entrypoint' decorator with the optional 'garden_doi' argument. Providing the decorator with a DOI\n",
    "     will override the Global DOI for that specific entrypoint.\n",
    "   - Base image name: The name of the garden base image you want to start this notebook with.\n",
    "     To see a list of the available Garden base images, see the dropdown menu under 'Base Image' below or \n",
    "     use 'garden-ai notebook list-premade-images'\n",
    "   - Requirements: Any additional requirements that should be installed in this notebook's container.\n",
    "     After making changes to your notebook's requirements, the widget will show a 'Install new requirements' button\n",
    "     that installs the new requirements to the container and updates your local requirements file if one was provided.\n",
    "\"\"\"\n",
    "\n",
    "from garden_ai.notebook_metadata import display_metadata_widget\n",
    "display_metadata_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H24yDUiVP5-n"
   },
   "source": [
    "## Your Model ðŸŒ±GardenðŸŒ± Execution Environment\n",
    "\n",
    "Use this notebook to write a function that executes your model(s). Tag that function with the `@entrypoint` decorator.\n",
    "\n",
    "Garden will take this notebook and build a container with it. When Garden executes your `@entrypoint`, it will be like like you have just run all the cells of this notebook once. So you can install libraries with `!pip install` and your function can use those libraries. You can also define helper functions and constants to use in your `@entrypoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qww1_jOzP5S9"
   },
   "outputs": [],
   "source": [
    "from garden_ai.model_connectors import create_connector\n",
    "from garden_ai import EntrypointMetadata, entrypoint, entrypoint_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b0s7Bealdp8M"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aikfsCRdrEZ"
   },
   "source": [
    "### Model connectors\n",
    "\n",
    "Model connectors let Garden import metadata about your model.\n",
    "They also have a `stage` method that you can use to download your model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H7em6SwMdvkt"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced1d6c7445d43899def7d6b1ba3f476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/33.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pydantic/main.py:214: UserWarning: A custom validator is returning a value other than `self`.\n",
      "Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\n",
      "See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "HFConnector(repo_url=Url('https://huggingface.co/bengal1/RTS'), repo_id='bengal1/RTS', branch='main', revision='30457d4779884d47bcf6c6fe0ba153a5c75885d3', local_dir=PosixPath('models/RTS'), enable_imports=True, metadata=ModelMetadata(model_identifier='bengal1/RTS', model_repository='huggingface.co', model_version='30457d4779884d47bcf6c6fe0ba153a5c75885d3'), readme='', model_dir='models')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hugging_face_repo = create_connector(\"https://huggingface.co/bengal1/RTS\", revision=\"30457d4779884d47bcf6c6fe0ba153a5c75885d3\")\n",
    "my_hugging_face_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTziKOq7d1Qs"
   },
   "source": [
    "### Entrypoint metadata\n",
    "\n",
    "\n",
    "To publish your function, Garden needs metadata so that other users can discover it.\n",
    "Edit this EntrypointMetadata object to describe your function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PHtZD33NhCEF"
   },
   "outputs": [],
   "source": [
    "rts_entrypoint_meta = EntrypointMetadata(\n",
    "    title=\"Retrogressive Thaw Slumps\",\n",
    "    description=\"Simplified example of training and running inference on a toy model using the Retrogressive Thaw Slumps (RTS) dataset.\",\n",
    "    authors=[\"Ben Galewsky\", \"Chia-Yu Hsu\"],\n",
    "    tags=[\"pytorch\", \"tutorial\"],\n",
    "    requirements=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnNDYs4PhKKO"
   },
   "source": [
    "### Helper Functions\n",
    "\n",
    "Define any helper functions you need and use them in the function you want to let people run remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hhd9FNB9hN0a"
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    from torchvision.io import read_image\n",
    "    from torchvision.transforms import v2 as T\n",
    "    transforms = []\n",
    "\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    transform =  T.Compose(transforms)\n",
    "\n",
    "\n",
    "    image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(\n",
    "        torch.uint8\n",
    "    )\n",
    "    image = image[:3, ...]\n",
    "    transformed_image = transform(image)\n",
    "\n",
    "    x = torch.unsqueeze(transformed_image, 0)\n",
    "\n",
    "    return x # [:3, ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDPkWjAShSKr"
   },
   "source": [
    "### Write your entrypoint function that will run remotely\n",
    "\n",
    "The `@entrypoint` decorator makes this function available to run in your garden when you publish the notebook.\n",
    "Download your model weights and call your model in this function.\n",
    "\n",
    "In the decorator be sure to include:\n",
    "- your entrypoint metadata,\n",
    "- connectors for any models you're using,\n",
    "\n",
    "You can add your entrypoint to a Garden in two different ways.\n",
    "\n",
    "If you want all entrypoints in this notebook be added to one Garden, set the `NOTEBOOK_GLOBAL_DOI` in your notebooks metadata or by using the `--doi` argument for `garden-ai notebook start`\n",
    "\n",
    "If you want to specify different Gardens for different entrypoints, provide each decorator with the optional `garden_doi` argument.\n",
    "\n",
    "If you both set the `NOTEBOOK_GLOBAL_DOI` and are providing a decorator with a DOI, the entrypoint will ONLY be added to the Garden given to the decorator.\n",
    "\n",
    "To see all the DOIs of your gardens, use `garden-ai garden list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6ls-44Wehec9"
   },
   "outputs": [],
   "source": [
    "@entrypoint(metadata=rts_entrypoint_meta,  model_connectors=[my_hugging_face_repo], garden_doi=\"10.26311/5fb6-f950\")\n",
    "def identify_rts(image_url):\n",
    "    import torch\n",
    "    import requests\n",
    "    import tempfile\n",
    "    from torchvision.io import read_image\n",
    "\n",
    "    download_path = my_hugging_face_repo.stage()\n",
    "    model = torch.load(download_path + \"/model.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "    response = requests.get(image_url)\n",
    "    with tempfile.NamedTemporaryFile(delete=True, suffix='.jpg') as tmp_file:\n",
    "        # Write the content to the temporary file\n",
    "        tmp_file.write(response.content)\n",
    "        tmp_file_path = tmp_file.name\n",
    "        image = read_image(tmp_file_path)\n",
    "\n",
    "        scaled_tensor = preprocess(image)\n",
    "        with torch.no_grad():\n",
    "            output = model(scaled_tensor)\n",
    "\n",
    "    def filter_predictions(pred, score_threshold=0.5):\n",
    "        keep = pred[\"scores\"] > score_threshold\n",
    "        return {k: v[keep] for k, v in pred.items()}\n",
    "\n",
    "    return filter_predictions(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK3PHq2fhgxp"
   },
   "source": [
    "### Test your entrypoint function\n",
    "\n",
    "Finally, make sure your `@entrypoint` works!\n",
    "When Garden makes a container from your notebook, it runs all the cells in order and saves the notebook. Then users invoke your `@entrypoint` in the context of the notebook.\n",
    "\n",
    "Note on testing: any test functions that call your entrypoint (like the one below) should be marked with `@entrypoint_test(<entrypoint_being_tested>)`. This is because calling an entrypoint typically causes side-effects (such as downloading your model weights to disk) that shouldn't be \"baked in\" to the environment of the final published notebook. \n",
    "\n",
    "Anything marked with `@entrypoint_test` won't be run at publication time, so you don't need to remember to comment out your test code before publishing. We'll also use `@entrypoint_test` functions as example code for others to see how your entrypoint expects to be called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pn2aa8wnhu2u"
   },
   "outputs": [],
   "source": [
    "@entrypoint_test(identify_rts)\n",
    "def test_run_my_model():\n",
    "    from torchvision.io import read_image\n",
    "    import requests\n",
    "    import tempfile\n",
    "\n",
    "    sample_image_url = \"https://github.com/cyber2a/Cyber2A-RTS-ToyModel/blob/main/data/images/valtest_nitze_008.jpg?raw=true\"\n",
    "    return identify_rts(sample_image_url)\n",
    "import os\n",
    "os.environ[\"GARDEN_SKIP_TESTS\"] = 'True'\n",
    "test_run_my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A9-UTFHAmCEq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c09295dbb749d88c362aabb214de08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([[ 69.4303, 134.2501, 111.9559, 173.3981]]), 'labels': tensor([1]), 'scores': tensor([0.6037]), 'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])}\n"
     ]
    }
   ],
   "source": [
    "sample_image_url = \"https://github.com/cyber2a/Cyber2A-RTS-ToyModel/blob/main/data/images/valtest_yg_055.jpg?raw=true\"\n",
    "print(identify_rts(sample_image_url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "garden_metadata": {
   "global_notebook_doi": null,
   "notebook_image_name": "3.11-torch",
   "notebook_image_uri": "gardenai/base:python-3.11-torch",
   "notebook_requirements": {
    "contents": [],
    "file_format": "pip"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
