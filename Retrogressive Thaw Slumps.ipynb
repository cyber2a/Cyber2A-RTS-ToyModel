{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyber2A Workshop: Toy Model for RTS Training and Inference\n",
    "This repository demonstrates a simplified example of training and running inference on a toy model using the Retrogressive Thaw Slumps (RTS) dataset. It is adapted from the official [PyTorch Vision Tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html).\n",
    "\n",
    "The copyright for the tutorial content belongs to PyTorch. Â© Copyright 2024, PyTorch.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(\"env.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJwhcR1hp41n"
   },
   "source": [
    "## Imports\n",
    "We have some code in a local module to keep this notebook focused on\n",
    "the training concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTcc_EsTaf-w"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"./toy_model\")\n",
    "\n",
    "import torch\n",
    "from dataset import RTSDataset\n",
    "from transforms import get_transform\n",
    "from utils import collate_fn\n",
    "from model import get_model_instance_segmentation\n",
    "from engine import evaluate, train_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdUrtBN-b4IA"
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "assert device.type == 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "These are the model hyperparameters. They are pulled out of the code to easily\n",
    "be set here. They will be recorded along with the run in the tracking server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"lr\": 0.005,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"step_size\": 3,\n",
    "    \"gamma\": 0.1,\n",
    "    \"epochs\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for Training\n",
    "Find the training data and set up the optomizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivUacz8vqkkv"
   },
   "outputs": [],
   "source": [
    "dataset = RTSDataset(\"data/coco_rts_train.json\", get_transform(train=True))\n",
    "dataset_test = RTSDataset(\"data/coco_rts_valtest.json\", get_transform(train=False))\n",
    "\n",
    "# Create data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = get_model_instance_segmentation(num_classes=2)\n",
    "model.to(device)\n",
    "\n",
    "# Set up optimizer and learning rate scheduler\n",
    "opt_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(opt_params, lr=params[\"lr\"], \n",
    "                            momentum=params[\"momentum\"], \n",
    "                            weight_decay=params[\"weight_decay\"])\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                               step_size=params[\"step_size\"], \n",
    "                                               gamma=params[\"gamma\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Input and Output Schemas\n",
    "MLFlow requires published models to include schemas for model input and inference\n",
    "output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.types import Schema, TensorSpec\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "# Define the input schema\n",
    "input_schema = Schema([\n",
    "    TensorSpec(\n",
    "        np.dtype(np.float32),\n",
    "        shape=(1, 3, 226, 288)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Define the output schema as a dictionary\n",
    "output_schema = Schema([\n",
    "    TensorSpec(\n",
    "        np.dtype(np.float32),\n",
    "        shape=(71, 4),  # Assuming boxes are in (x1, y1, x2, y2) format\n",
    "        name=\"boxes\"\n",
    "    ),\n",
    "    TensorSpec(\n",
    "        np.dtype(np.int64),\n",
    "        shape=([71]),  # One label per detection\n",
    "        name=\"labels\"\n",
    "    ),\n",
    "    TensorSpec(\n",
    "        np.dtype(np.float32),\n",
    "        shape=([71]),  # One confidence score per detection\n",
    "        name=\"scores\"\n",
    "    ),\n",
    "    TensorSpec(\n",
    "        np.dtype(np.float32),\n",
    "        shape=(71, 1, 226, 288), \n",
    "        name=\"masks\"\n",
    "    )\n",
    "])\n",
    "\n",
    "signature = mlflow.models.signature.ModelSignature(\n",
    "    inputs=input_schema,\n",
    "    outputs=output_schema\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Training Run\n",
    "This will start the run, log the hyperparameters and then log metrics from the model\n",
    "as the training progresses.\n",
    "\n",
    "When training is complete, the model is uploaded to Tracking Server and associated with the training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGB5zYksttZ_",
    "outputId": "fe7f3fb3-1f31-47b8-b4b9-0cf3b5b1c62c"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.set_tag(\"scientist\", \"Ben\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(params[\"epochs\"],):\n",
    "        metrics = train_one_epoch(model, \n",
    "                                  optimizer, \n",
    "                                  data_loader, \n",
    "                                  device, \n",
    "                                  epoch, \n",
    "                                  print_freq=10)\n",
    "        lr_scheduler.step()\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "    print(metrics)\n",
    "    \n",
    "    model_info = mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare an image to Perform Inference on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_model.transforms import get_transform\n",
    "from torchvision.io import read_image\n",
    "\n",
    "def preprocess_image(image_path, transform, device):\n",
    "    image = read_image(image_path)\n",
    "    image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(\n",
    "        torch.uint8\n",
    "    )\n",
    "    image = image[:3, ...]\n",
    "    transformed_image = transform(image)\n",
    "    return image, transformed_image[:3, ...].to(device)\n",
    "\n",
    "\n",
    "image, transformed_image = preprocess_image(\n",
    "    \"data/images/valtest_yg_055.jpg\", get_transform(train=False), device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "model_uri = model_info.model_uri\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri, model_config={'device': 'cuda'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model.metadata.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The pyfunc flavor doesn't handle our input data, \n",
    "# we could write a custom flavor wrapper, for now\n",
    "# just get our hands on the raw torch model\n",
    "pytorch_model = loaded_model._model_impl.pytorch_model\n",
    "\n",
    "x = torch.unsqueeze(transformed_image, 0)\n",
    "\n",
    "pred = pytorch_model(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(p, score_threshold=0.5):\n",
    "    keep = p[\"scores\"] > score_threshold\n",
    "    return {k: v[keep] for k, v in p.items()}\n",
    "\n",
    "filtered = filter_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the Predicted Boxes on Top of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "import cv2\n",
    "def draw_predictions(image, pred):\n",
    "    pred_labels = [f\"RTS: {score:.3f}\" for score in pred[\"scores\"]]\n",
    "    masks = (pred[\"masks\"] > 0.7).squeeze(1)\n",
    "    output_image = draw_segmentation_masks(image, masks, alpha=0.5, colors=\"red\")\n",
    "    pred_boxes = pred[\"boxes\"].long()\n",
    "    output_image = draw_bounding_boxes(\n",
    "        output_image, pred_boxes, pred_labels, colors=\"black\", width=0\n",
    "    )\n",
    "    return output_image\n",
    "    \n",
    "output_image = draw_predictions(image, filtered)\n",
    "\n",
    "i1=output_image.permute(1, 2, 0).numpy()\n",
    "i2=cv2.cvtColor(i1, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(i2)\n",
    "plt.axis('off')  # Optional: Hides the axis ticks and labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "plt.axis('off')  # Optional: Hides the axis ticks and labels\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
